\documentclass[a4paper,15pt]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[english, polish]{babel}
\usepackage[utf8]{inputenc}   % lub utf8
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{anysize}
\usepackage{enumerate}
\usepackage{times}
\usepackage{caption}
\usepackage{titlesec}
\usepackage{float}
\usepackage{titleps,kantlipsum}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{framed}
\usepackage{tcolorbox}
\lstloadlanguages{Matlab}
 
\usepackage[justification=centering]{caption}
\titlelabel{\thetitle.\quad}

\pagenumbering{arabic}

\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{%
  \parbox{\textwidth}{\colorbox{darkgreen}{\parbox{\textwidth}{#1#2#3}}\vskip-4pt}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\lstset{frame=lrb,xleftmargin=\fboxsep,xrightmargin=-\fboxsep}

% Definicja nowego stylu strony
\newpagestyle{mypage}
{
  \headrule
  
  \sethead
  { \MakeUppercase{\thesection\quad \sectiontitle} } 
  {}
  {\thesubsection\quad \subsectiontitle}
  
  \setfoot
  {}
  {}
  {\thepage}
}

\newpagestyle{mypage_1}
{
	\headrule
	
	\sethead
	{  }
	{\MakeUppercase{Podstawy sztucznej inteligencji}}
	{}
	
	\setfoot
	{}
	{\thepage}
	{}
}

\settitlemarks{section,subsection,subsubsection}

\pagestyle{mypage_1}

\newcommand{\ask}[2]{
    \begin{tcolorbox}[colback=black!5!white,colframe=gray,title={Pytanie #1}]
        #2
    \end{tcolorbox}
}

\newcommand{\ex}[2]{
    \begin{tcolorbox}[colback=black!5!white,colframe=black,title={Zadanie #1}]
        #2
    \end{tcolorbox}
}

%\marginsize{left}{right}{top}{bottom}
\marginsize{3cm}{3cm}{3cm}{3cm}
\sloppy
\titleformat{\section}
  {\normalfont\Large\bfseries}{\thesection}{1em}{}[{\titlerule[0.8pt]}]
 
 \definecolor{darkred}{rgb}{0.9,0,0}
\definecolor{grey}{rgb}{0.4,0.4,0.4}
\definecolor{orange}{rgb}{1,0.6,0.05}
\definecolor{darkgreen}{rgb}{0.2,0.5,0.05}
 
\definecolor{mGreen}{RGB}{2,217,39}
\definecolor{mGray}{rgb}{0.5,0.5,0.5}
\definecolor{mPurple}{RGB}{223,32,214}
\definecolor{mKeyword}{RGB}{204,152,15}
\definecolor{backgroundColour}{RGB}{68,68,68}
\definecolor{commentColor}{RGB}{243,253,254}


\lstdefinestyle{Ada}{
    backgroundcolor=\color{backgroundColour},   
    commentstyle=\color{commentColor},
    keywordstyle=\color{mKeyword},
	basicstyle=\color{mGreen}\footnotesize,    
    numberstyle=\tiny\color{mPurple},
    stringstyle=\color{mPurple},
    breakatwhitespace=false,         
    breaklines=true,                 
    %captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=C
}

\lstset{style=Ada}

\newcommand{\Hilight}{\makebox[0pt][l]{\color{cyan}\rule[-4pt]{0.65\linewidth}{14pt}}}


\begin{document}



\tableofcontents

\newpage
\section{Źródła}
Na podstawie:
\begin{itemize}
\item Artificial Intelligence - Foundations of computational agents (książka w internecie)
\item Fajny link do sieci neuronowych: \url{https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/}
\end{itemize}

\section{Kartkówka 1 - Uczenie nadzorowane}

\subsection{Wiadomości podstawowe}

\subsubsection{ML workflow}
Czyli ogólny cykl MachineLearning, przechodzimy przez kolejne fazy w celu uzyskania rezultatów.
\begin{itemize}
\item Wstępne przygotowanie danych - zebranie danych, analiza danych, czyszczenie danych, normalizacja itd.
\item Przygotowanie danych - integracja danych, filtrowanie, redukcja itd.
\item Tworzenie zbiorów testowych
\item Algorytmy i modele uczenia maszynowego - wybór, testowanie, dobieranie parametrów, wybór najlepszego
\item Testy A/B i wdrożenie produkcyjne
\end{itemize}

\subsubsection{Typy uczenia}
Wyróżnia się wiele kategoryzacji uczenia, jednym z podziałów jest podział ze względu na sposób działania algorytmów:
\begin{itemize}
\item Uczenie nadzorowane (supervised learning) - mamy dane atrybuty wejściowe oraz atrybuty wyjściowe, a także zbiór trenujący, który zawiera konkretne dane z atrybutami wejściowymi i wyjściowymi. Zadanie polega na przewidzeniu wartości cech atrybutów wyjściowych mając dane wartości cech atrybutów wejściowych dla zbioru testowego. Formalnie problemy te nazywane są \textbf{klasyfikacja} (kiedy wartości atrybutów wyjściowych są dyskretne) oraz \textbf{regresja} (kiedy wartości atrybutów wyjściowych są ciągłe) 

\item Uczenie nienadzorowane (unsupervised learning) - w tych problemach nie mamy określonych atrybutów wyjściowych jak w uczeniu nadzorowanym. Inteligentny agent sam musi odkryć kategorie i wzory w analizowanych danych. Przykładową techniką stosowaną przez uczenie nienadzorowane jest klasteryzacja (klastry powstają na podstawie zauważenia podobieństwa pomiędzy atrybutami wejściowymi, nie ma jasno powiedziane dla jakich wartości wejściowych ma być dana wartość wyjściowa jak jest to w uczeniu nadzorowanym) 


\item Uczenie przez wzmacnianie (reinforcement learning) - w tych problemach inteligentny agent próbuje wykonywać jakieś akcje w celu uzyskania danych, a następnie określa czy podjęta akcja była korzystna czy nie (punishment lub reward). Podejście takie jest w niektórych przypadkach konieczne, wyobraźmy sobie np., że chcemy nauczyć robota chwytać przedmiot - bardzo trudno będzie nam stworzyć zbiór danych, który będzie zawierał wszystkie możliwe współrzędne oraz wszystkie możliwe ruchy. W takim przypadkach chcemy aby inteligentny agent sam potrafił zebrać dane i ocenić poprawność swoich akcji. 
\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi2.png}}
\end{figure}

\item Inne - istnieje wiele innych, które jak na razie z naszego punktu widzenia są mniej ważne
\end{itemize}

Kolejnym podziałem jest podział uwzględniający dostęp do danych:
\begin{itemize}
\item offline - wszystkie dane ze zbioru trenującego są dostępne dla agenta zanim ten ma podjąć jakąś decyzje 
\item online - dane przychodzą podczas gdy agent się uczy
\item active - to rodzaj uczenia online, które polega na tym, że agent sam stwierdza, które przykłady byłyby dla niego użyteczne i stara się je uzyskać 
\end{itemize}


\subsubsection{Zbiór uczący(trenujący, training), testowy i walidacyjny}

\begin{itemize}
\item uczący - zbiór danych na którym uczy się agent, zawiera zarówno wartości atrybutów wejściowych jak i wyjściowych
\item zbiór testowy - zbiór danych na którym testowane jest czego agent się nauczył, zawiera tylko wartości dla atrybutów wejściowych
\item zbiór walidacyjny - używany jest w celu zbadania czy zbudowany model działa poprawnie i dostosowania jego parametrów
\end{itemize}

Zbiory te powinny być niezależne, zbiór testowy ma służyć do sprawdzenia jak dobrze inteligentny agent potrafi podejmować decyzje. 

\subsubsection{Reprezentacja}

Każdy inteligentny agent musi posiadać jakąś reprezentacje danych na podstawie których ma podejmować decyzje. Im więcej danych zawiera reprezentacja, tym bardziej użyteczna do tworzenia rozwiązań. 

Z drugiej strony im większa reprezentacja tym trudniej się uczyć, ponieważ wymaga to operacji na dużej liczbie danych. Konieczne jest więc znalezienie kompromisu. 

Machine learning jest najczęściej omawiany w kontekście konkretnej reprezentacji, ważne jest więc aby znać podstawowe z nich. 


\subsubsection{Noise}

Noise to termin odnoszący się do pewnych zaburzeń w danych (np. brak części danych, część danych nieprawidłowa itp.), jedną z pierwszych faz w machine learningu jest czyszczenie danych, które to polega między innymi na usuwaniu hałasu z danych, można to zrobić między innymi przy pomocy interpolacji (przewidywanie wartości która znajduje się pomiędzy innymi) lub ekstrapolacji (przewidywanie wartości, które jeszcze nie są znane)


\subsection{Uczenie nadzorowane}

Na wejściu procesu uczenia nadzorowanego jest:
\begin{itemize}
\item zbiór atrybutów, a wśród nich podział na
\begin{itemize}
\item wejściowe
\item wyjściowe
\end{itemize}
\item dziedziny atrybutów - każdy z atrybutów ma swoją dziedzinę, czyli zbiór wartości jakie może przyjmować, dziedzina może być dyskretna (zbiór skończony) lub ciągła
\item zbiór przykładów, czyli zebrane dane, które dzielimy na
\begin{itemize}
\item zbiór uczący - w którym wartości są znane zarówno dla atrybutów wejściowych jak i wyjściowych
\item zbiór testujący - w którym wartości są znane tylko dla atrybutów wejściowych
\end{itemize}
\end{itemize}
Celem uczenia nadzorowanego jest przewidzieć wartości atrybutów wyjściowych zbioru testowego na podstawie atrybutów wejściowych. 


\subsection{Modele uczenia nadzorowanego}

Nauczony model to po prostu funkcja, która bierze na wejściu określone wartości atrybutów wejściowych i zwraca na wyjściu pewne wartości atrybutów wyjściowych. 

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi1.png}}
\end{figure}

Poniżej omówione zostaną podstawowe modele dla uczenia nadzorowanego. 

\subsubsection{Drzewa decyzyjne (decision trees)}
Służy do realizacji uczenia nadzorowanego, które oparte jest na klasyfikacji (dyskretne dziedziny atrybutów). Jest to jedna z podstawowych i najprostszych technik. Drzewo takie tak naprawdę reprezentuje funkcję dyskretną, która przyporządkowuje dyskretnym wartościom atrybutów wejściowych dyskretne wartości atrybutów wyjściowych. \\
Drzewo decyzyjne to drzewo, które:
\begin{itemize}
\item każdy węzeł, który nie jest liściem ma etykietę będącą warunkiem 
\item każdy węzeł, który nie jest liściem ma dwoje dzieci, jeden z etykietą \textit{true}, a drugi z etykietą \textit{false}
\item każdy liść zawiera wartość atrybutu wyjściowego
\end{itemize}

Przykładowe dane i drzewo decyzyjne utworzone na ich podstawie:

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi4.png}}
\end{figure}


\begin{figure}[H]
\centerline{\includegraphics[scale=1]{psi3.png}}
\end{figure}

Drzewo na prawo podejmuje decyzje na podstawie prawdopodobieństwa (zna tylko jedną wartość dla atrybutu long), a drzewa na lewo pozwala w sposób deterministyczny określić wartość atrybutu wyjściowego, bierze pod uwagę wszystkie atrybuty. 


\subsubsection{Regresja liniowa (linear regression)}

Regresja liniowa to model, który pozwala dopasować funkcję liniową do zbioru danych uczących w przypadku gdy dziedzina atrybutów jest ciągła. 

\begin{figure}[H]
\centerline{\includegraphics[scale=1]{psi5.png}}
\end{figure}

Problem, który teraz powstaje jest oczywiście jak znaleźć wektor wag w tym równaniu, z pomocą przychodzi nam tutaj równanie, które opisuje jak dobrze funkcja wpasowuje się w dane, czyli równanie opisujące sumę kwadratów błędu, minimalizacja takiej funkcji pozwala na znalezienie wektora wag. 

\begin{figure}[H]
\centerline{\includegraphics[scale=1]{psi6.png}}
\end{figure}

Nie w każdym przypadku możliwe jest jednak obliczenie wartości tych wag poprzez minimalizacje błędu, czasami konieczne jest zastosowanie innych metod iteracyjnych, jedną z takich metod jest metoda gradientowa. \\

Metoda gradientowa to metoda iteracyjna pozwalająca na znalezienie minimum funkcji. Metoda ta bazuje na obliczaniu pochodnych cząstkowych po każdej z wag i zmianie wartości wag proporcjonalnie do obliczonych wartości pochodnych. 

\subsection{Nadmierne dopasowanie, przeuczenie, przetrenowanie (overfitting)}

Nadmierne dopasowanie to sytuacja w której agent podejmuje poprawne decyzje na zbiorze uczącym, ale nie podejmuje poprawnych decyzji na zbiorze testowym lub innym z którego weźmiemy dane. Oznacza to, że agent został nauczony tylko na tych konkretnych danych, które znajdywały się w zbiorze uczącym i na nich działa dobrze, ale nie przekłada się to na ogólnie poprawne funkcjonowanie algorytmu dla ogólnych danych. Można więc powiedzieć, że model 'działa' tylko w pewnym szczególnym przypadku, a tak naprawdę nie działa wcale, ponieważ nie robi tego co powinien na danych ogólnych.  \\

Powodami nadmiernego dopasowania mogą być:
\begin{itemize}
\item niepoprawnie przygotowanie danych wejściowych - obecne w danych noise, randomness 
\item zbyt mała liczba przykładów w zbiorze wejściowym - np. jedna ocena 5-gwiazdkowa, to za mało aby orzec o 5-gwiazdkowej jakości
\item zbyt duża liczba przykładów w zbiorze wejściowym - gdy każdy przykład ma inne wartości, trudno jest znaleźć jakąkolwiek zależność pomiędzy nimi, np. mamy mnóstwo danych o pacjentach, ale każdy z nich ma inne dolegliwości
\item złożoność modelu - przykładowo, stosując regresje, nie zawsze wielomian o wyższym stopniu będzie lepszy
\end{itemize}

\subsubsection{Metody zapobiegania nadmiernemu dopasowaniu}

Istnieje wiele metod których celem jest zapobieganie nadmiernemu dopasowaniu. Jedną z najbardziej popularnych jest walidacja krzyżowa. \\

Walidacja krzyżowa polega na podziale zbioru uczącego na dwie równe części i użycie jednej z części jako zbioru testowego. Wadą tej metody jest jednak to, że taki podział powoduje znaczną utratę danych na których uczy się model (aż połowa !) dlatego częściej stosowanym rozwiązaniem jest metoda k-złożeń walidacji krzyżowych (k-fold cross validation). \\

W metodzie k-cross validation zbiór uczący znów dzielimy na części, ale tym razem jest ich \textit{k}. Następnie przeprowadzamy uczenie na \textit{k-1} z nich, a pozostały jeden stosujemy do walidacji. Czynność tą powtarzamy dla wszystkich możliwych kombinacji. 

\begin{figure}[H]
\centerline{\includegraphics[scale=1]{psi7.png}}
\end{figure}


\subsection{Sieci neuronowe}

Sieć neuronowa to model, który został zainspirowany biologiczną budową mózgu. Ma architekturę sieci składającej się z warstw, warstwy z kolei składają się z neuronów, graficznie przedstawiamy neurony jako koła. Cała struktura zawiera parametry, które są dostosowywane w celu wykonania pewnego zadania. \\
Pierwszą warstwą jest zawsze warstwa wejść, neurony w tej warstwie zawierają zawsze tylko jedną liczbę rzeczywistą o wartości pomiędzy 0 i 1. \\
Ostatnią warstwą jest zawsze warstwa wyjściowa, tutaj neurony również zawierają zawsze tylko jedną liczbę pomiędzy 0 i 1. \\
Wszystkie warstwy pośrednie nazywane są warstwami ukrytymi. 

\begin{figure}[H]
\centerline{\includegraphics[scale=1]{psi8.png}}
\end{figure}

Połączenia pomiędzy warstwami mają przypisane wagi, które są dowolnymi liczbami rzeczywistymi, wartość z neuronu z poprzedzającej warstwy jest mnożona przez wagę, operacja ta jest wykonywana dla wszystkich neuronów, które mają połączenia z neuronem w następnej warstwie, wartości wynikowe są dodawane do siebie i tworzą sumę. \\ 

Oczywiście suma ta może być dowolną wartością, nie musi być z przedziału 0 do 1, dlatego stosuje się specjalną funkcję, która skaluje sumę tak aby mogła być przechowywana w neuronie w następnej warstwie. \\

Ostatecznie dostajemy liczbę rzeczywistą pomiędzy 0 i 1 w neuronie wynikowym i ta liczba określa prawdopodobieństwo, że coś można zakwalifikować do danej klasy (takiej którą reprezentuje dany neuron). \\

Cała sztuka polega na odpowiednim dobraniu wszystkich wag, tak aby przy odpowiednich danych wejściowych, otrzymywać poprawną klasyfikację. Proces dobierania wag dla sieci neuronowej nazywamy trenowaniem/uczeniem sieci. Proces ten realizowany jest na podstawie poprawnych klasyfikacji, które są już nam znane (w uczeniu nadzorowanym), ale sieci neuronowe mogą być także stosowane w innych rodzajach uczenia. \\

\subsection{Backpropagation}

To algorytm, który jest stosowany do efektywnego uczenia się sieci neuronowych, opiera się o zastosowanie metody gradientowej. 

\section{Kartkówka 2 - Uczenie nienadzorowane}

\subsection{Uczenie nienadzorowane}
W tym rodzaju uczenia nie mamy danych atrybutów wyjściowych dla zbioru uczącego, a jedynie dane w tym zbiorze. Zadaniem uczenia nienadzorowanego jest odkrycie klasyfikacji jakiej można dokonać na danych.

\subsection{Klasteryzacja}
Jedną ogólną metodą do realizacji uczenia nienadzorowanego jest klasteryzacja, metoda ta dzieli przykłady ze zbioru danych na klastry (klasy). Klasa jest przewidywaniem wartości dla przykładów z tej klasy. Każda klasteryzacja obarczona jest błędem predykcji, najlepsza klasteryzacja to taka, która minimalizuje ten błąd. \\
Klasteryzacja jest tylko ogólnym schematem postępowania, konkretne metody implementują ten schemat postępowania (np. k-Means).

\subsubsection{Hard clustering}
W \textit{hard clustering} każdy przykład jest definitywnie umieszczany w pewnej klasie. Ta klasa jest następnie używana do przewidzenia przyszłych wartości tego przykładu. 

\subsubsection{Soft clustering}
W \textit{soft clustering} każdy z przykładów ma rozkład prawdopodobieństwa dla przynależności do danej klasy. Przewidywanie przyszłych wartości dla danego przykładu jest średnią ważoną przewidywań dla klas w których znajduje się dany przykład, wagami tej średniej są prawdopodobieństwa, że przykład znajduje się w danej klasie.

\subsection{k-Means}
\begin{itemize}
\item realizuje założenia silnej klasteryzacji (hard clustering)
\item wejście do algorytmu są przykłady ze zbioru uczącego oraz liczba klas \textit{k}
\item wyjściem jest funkcja, która każdemu przykładowi przyporządkowuje klasę
\item każda z klas ma przypisane do niej wartości atrybutów
\item minimalizacja błędu polega na znalezieniu klas oraz przypisania ich do przykładów w takim sposób aby różnice pomiędzy wartościami dla klas i przykładów były jak najmniejsze
\end{itemize}

\subsubsection{Działania k-Means}
\begin{itemize}
\item Na początku algorytm randomowo przydziela klasy do przykładów
\item Następnie przechodzi w iteracyjną procedurę, której celem jest minimalizacja błędu:
\begin{itemize}
\item algorytm oblicza 'odległości' (błąd) przykładów od danej klasy
\item na tej podstawie wartości atrybutów w klasie są aktualizowane
\item itd. aż do osiągnięcia braku poprawy 
\end{itemize}
\end{itemize}


\subsection{EM - Expectation Maximisation}
\begin{itemize}
\item realizuje założenia słabej klasteryzacji (soft clustering)
\item algorytm nie przypisuje definitywnie przykładów do grup jak robił to k-Means, ale estymuje prawdopodobieństwo, że dany przykład należy do danej klasy
\item algorytm korzysta z założeń o wielowymiarowym rozkładzie normalnym danych 
\end{itemize}

\subsubsection{Działanie EM}
\begin{itemize}
\item Dla aktualnych parametrów rozkładu danych, przypisz prawdopodobieństwo przynależności do grup
\item Zamień aktualne parametry rozkładu na bliższe zgodności z danymi korzystając z prawdopodobieństwa przynależności z poprzedniego kroku
\end{itemize}

\subsubsection{Mieszanki gaussowskie}
To rozkład prawdopodobieństwa stosowany dla ciągłych zbiorów danych, stosowany jest w metodzie EM.


\subsection{Klasteryzacja hierarchiczna}
\begin{itemize}
\item Algorytm klasteryzacji, który nie zakłada z góry liczby klastrów
\item Początkowo każdy przykład jest osobnym klastrem i są one łączone aż do uzyskania jednego klastra (procedura aglomeracyjna) lub w drugim podejściu:
\item Początkowo wszystkie przykłady tworzą jeden klaster, który następnie jest dzielony aż do uzyskania oddzielnego klastra z każdego przykładu
\item Dzielenie i łączenie odbywa się na podstawie tzw. macierzy odległości (podobieństw), która zwiera odległości pomiędzy klastrami
\item Najbliżej położone względem siebie klastry są razem łączone
\end{itemize}
Proces klasteryzacji hierarchicznej przedstawia się często w postaci tzw. dendogramu:

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi17.png}}
\end{figure}




\subsection{Reguły asocjacyjne (analiza koszykowa) i algorytmy ich generacji}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi10.png}}
\end{figure}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi11.png}}
\end{figure}


Reguły asocjacyjne kojarzą konkretny wniosek (np. decyzję o zakupie konkretnego produktu) ze zbiorem warunków (np. zakupem kilku innych produktów). Na przykładzie z obrazka jedną z reguł może być to, że beer często występuje wtedy, gdy jednocześnie występują cannedveg i frozenmeal. 

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi9.png}}
\end{figure}

\subsubsection{Wsparcie i wiarygodność}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi12.png}}
\end{figure}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi13.png}}
\end{figure}

\subsubsection{Algorytmy znajdywania reguł asocjacyjnych}

Algorytmy wykorzystywane do znajdowania reguł stosują metodę generowania i testowania — początkowo generują proste reguły i walidują je względem zbioru danych. Dobre reguły są zachowywane, a wszystkie reguły, z zachowaniem różnych ograniczeń, podlegają specjalizacji. Specjalizacja polega na dodawaniu warunków do reguły. Uzyskane nowe reguły są walidowane względem danych i proces znów zapisuje najlepsze i najbardziej interesujące reguły. 

\subsubsection{Algorytm apriori}

Jeden z najwydajniejszych i najbardziej popularnych algorytmów generowania reguł asocjacyjnych (analizy koszykowej). Funkcje implementujące ten algorytm posiadają dwa główne kroki: \\

\textbf{Łączenie}: do zbioru $C_k$ wstawiamy sumy takich par $X,Y$ $\in$ $F_{k-1}$, które mają wspólne k-2 początkowych elementów np.

dla $F_{k-1}={AB, AC, AD, AE, BC, BD, BE}$

mamy: $C_k={ABC, ABD, ABE, ACD, ACE,ADE, BCD, BCE, BDE}$ \\

\textbf{Obcinanie}: Celem operacji jest redukowanie rozmiaru zbioru $C_k$ przed sprawdzaniem ich wsparcia w bazie transakcji. W tym celu wykorzystujemy własciwość Apriori, z której wynika, że jeśli jakiś (k-1)-podzbiór danego kandydata nie występuje w $F_{k-1}$, to ten kandydat powinien być usunięty z $C_k$.

otrzymujemy zatem: $C_k={ABC, ABD, ABE}$ 

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi16.png}}
\end{figure}






\subsection{Inne typy learningu}

\subsubsection{Transfer learning}
Uczenie transferowe stosujemy, gdy chcemy wykorzystać już istniejący model w odniesieniu do nowego, powiązanego problemu. Przykład: algorytm rozpoznający przechodniów na nocnych zdjęciach wykorzystujemy do rozpoznawania ich także na zdjęciach w oświetleniu dziennym. Zadanie to byłoby utrudnione lub niemożliwe z wykorzystaniem tradycyjnych technik nadzorowanych uczenia maszynowego. 

\subsubsection{Ensemble learning}
Technika uczenia maszynowego łącząca kilka algorytmów w celu osiągnięcia modelu o lepszej wydajności.

W przeciwieństwie do tradycyjnych modeli uczenia nadzorowanego, gdzie algorytm przeszukuje zestaw hipotez w celu znalezienia najbardziej optymalnej, ensemble learning pozwala na grupowanie kilku hipotez w celu utworzenia jednej, w założeniu lepszej od pozostałych.

Podstawą działania są drzewa decyzyjne określające definicje i wskazujące metody zespołowe. Drzewo takie określa wartość decyzją na podstawie serii pytań i warunków, a na następnie rozważa czynniki i podejmuje decyzje albo zadaje kolejne pytanie, dotyczące każdego z nich. 


\newpage
\section{Kartkówka 3 - Reprezentacja niepewności}

\subsection{Opis problemu}

Problem występuje w przypadkach gdy inteligentny agent nie jest pewien na 100\%, że dane informacje są prawdziwe. Zamiast tego agent przyjmuje, że dane informacje są prawdziwe z pewnym prawdopodobieństwem. \\

Przykładem takiej sytuacji może być diagnozowanie pacjenta. Lekarz nigdy nie wie w 100\% co się dzieje w środku pacjenta (no nie zaglądnie tam i nie sprawdzi) dlatego pewne założenia (pewne informacje, pewną wiedzą) przyjmuje z jakimś prawdopodobieństwem. \\



We wszystkich tego rodzaju przypadkach mamy do czynienia z niepewnością. Niepewność może wynikać np. z niemożliwości uzyskania całkowitej informacji lub niedeterminizmu. Do formalnej reprezentacji niepewności stosujemy teorie prawdopodobieństwa. 
 

\subsection{Stan wiary (belief state)}
Pojęcie to określa jeden ze sposobów radzenia sobie z niepewnością w podejmowaniu decyzji przez inteligentnego agenta. W tym podejściu należy zdefiniować wszystkie możliwe stany w jakich może znaleźć się agent, a następnie w każdym z tych stanów każdej tezie przypisujemy pewne prawdopodobieństwo. Metoda ta jest jednak mało praktyczna ze względu na konieczność reprezentacji wszystkich możliwych stanów agenta, co jest rzadko możliwe w praktyce. 


\subsection{Przypomnienie podstaw prawdopodobieństwa}

\subsubsection{Obserwacja $\omega$}
Obserwacja to po prostu pewien zaobserwowany fakt z rzeczywistości, którą opisujemy, np. "W rzucie kostką wypadło 6 oczek". Pojedynczą obserwację oznaczamy symbolem $\omega$. Rozpatrując dane zagadnienie mamy wiele obserwacji, przykładowo w rzucie kostką może wypaść 1,2,3,4,5 lub 6 oczek. Każdy z tych przypadków jest oddzielną obserwacją, a zbiór ich wszystkich oznaczamy symbolem $\Omega$.

\subsubsection{Miara prawdopodobieństwa $P(\omega)$}
Miara prawdopodobieństwa to funkcja P mapująca obserwacje na dowolne nieujemne liczby rzeczywiste (chociaż najczęściej przyjętą konwencją jest przedział [0;1]), taka że:
\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi18.png}}
\end{figure}

\subsubsection{Zmienna losowa \textit{X}}
Jeśli mamy jakieś zjawisko to często chcielibyśmy przyjąć pewną reprezentację zjawisk, które w nim zachodzą. Przykładowo w rzucie kostką, wynik każdego z rzutów chcielibyśmy zapisać za pomocą jednej liczby 1,2,3,4,5 lub 6, tak aby nie musieć określać za każdym razem wyniku jako 'Wypadło 3 oczka'. Do tego właśnie służy zmienna losowa, każdej z  obserwacji przypisujemy jakąś wartość z dziedziny tej zmiennej. Zmienne losowe oznaczmy dużymi literami, przykładowo \textit{X, Y}. Dziedzina zmiennej losowej może być dyskretna lub ciągła. 

\subsubsection{Rozkład prawdopodobieństwa zmiennej losowej \textit{P(X)}}

To funkcja, która określa prawdopodobieństwo, że zmienna losowa przyjmie określoną wartość ze swojej dziedziny. Np. $P(X=1)=\frac{1}{6}$, oznacza, że prawdopodobieństwo, że zmienna losowa będzie miała wartość 1 wynosi $\frac{1}{6}$.


\subsubsection{Prawdopodobieństwo warunkowe}
Prawdopodobieństwo warunkowe $P(h | e)$ to prawdopodobieństwo prawdziwości formuły $h$ przy znanym fakcie (wartości) $e$.
Wyprowadzenie wzoru na prawdopodobieństwo warunkowe:

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi19.png}}
\end{figure}


\subsubsection{Reguła Bayesa}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{psi20.png}}
\end{figure}


\subsubsection{Wartość oczekiwana}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{psi21.png}}
\end{figure}

\subsection{Niezależność}

Używając tylko standardowych aksjomatów o prawdopodobieństwie, pełny rozkład prawdopodobieństwa dla n zmiennych, wymagany do obliczania prawdopodobieństw warunkowych, składa się z $2^{n-1}$ wartości. Aby zmniejszyć tę liczbę należy wykorzystać niezależność warunkową, czyli założenie, że każda zmienna zależy bezpośrednio tylko od kilku innych.

Użycie twierdzeń o niezależności może radykalnie zmniejszyć ilość informacji niezbędnych do określenia pełnego rozkładu. Jeśli pełny zbiór zmiennych można podzielić na niezależne podzbiory, wtedy pełny rozkład można rozłożyć na osobne rozkłady tych podzbiorów. 

\subsection{Niezależność warunkowa}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{psi22.png}}
\end{figure}

\subsection{Niezależność bezwarunkowa}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{psi23.png}}
\end{figure}

\subsection{Naiwny klasyfikator Bayesa NBC}

Naiwny klasyfikator Bayesa to klasyfikator statystyczny, który działa przy założeniu, że parametry wejściowe są warunkowo niezależne od siebie nawzajem pod warunkiem parametru wyjściowego. Można to przedstawić za pomocą sieci Bayesowskiej, w której parametr wyjściowy nie ma żadnych rodziców, a każdy parametr wejściowy ma tylko jednego rodzica - parametr wyjściowy. Model ten wymaga znajomości prawdopodobieństwa $P(Y)$ parametru wyjściowego $Y$ i prawdopodobieństw warunkowych $P(X_i | Y)$ każdego z parametrów wejściowych $X_i$.

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi24.png}}
\end{figure}

Powyższy model może służyć do przewidzenia akcji użytkownika (czy przeczyta artykuł) przy znanych: autorze, wątku/temacie, długości i miejscu czytania jakiegoś artykułu. 


\subsection{Sieci Bayesowskie}
Sieci bayesowskie są rodzajem probabilistycznego modelu graficznego, który wykorzystuje wnioskowanie bayesowskie do obliczeń prawdopodobieństwa. Sieci bayesowskie mają na celu modelowanie zależności warunkowej poprzez reprezentowanie jej przez krawędzie na grafie kierunkowym. \\

Bardziej formalna definicja: \\

Sieć bayesowska to skierowany graf acykliczny, w którym każda krawędź odpowiada warunkowej zależności, a każdy węzeł odpowiada unikalnej zmiennej losowej:
\begin{itemize}
\item Każdy węzeł odpowiada zmiennej losowej, która może być dyskretna lub ciągła.
\item Jeśli istnieje krawędź od węzła X do węzła Y, mówi się, że X jest rodzicem Y. Graf ten jest skierowanym grafem acyklicznym, czyli takim który nie posiada cyklów skierowanych
\item Każdy węzeł $X_i$ ma warunkowy rozkład prawdopodobieństwa $P(X_i | Parents (X_i))$, który określa wpływ rodziców na dany węzeł.
\end{itemize}
Znaczenie strzałki z węzła $X$ do $Y$ jest zwykle takie, że $X$ ma bezpośredni wpływ na $Y$, co sugeruje, że "przyczyny" powinny być rodzicami efektów. Po ustaleniu topologii sieci Bayesowskiej musimy jedynie określić warunkowy rozkład prawdopodobieństwa dla każdej zmiennej, biorąc pod uwagę jej rodziców. 

\subsubsection{Przykład 1}
W tym przykładzie zmienna Weather jest niezależna od innych zmiennych a Toothache jest warunkowo niezależny od Catch.

\begin{figure}[H]
\centerline{\includegraphics[scale=0.75]{psi25.png}}
\end{figure}

Formalnie na warunkową niezależność Toothache i Catch od Cavity, wskazuje na brak powiązania między nimi (Toothache i Cavity). Z tego prostego przykładu możemy wywnioskować, że 
\begin{itemize}
\item Cavity jest bezpośrednią przyczyną Tootchache i Catch
\item Nie ma bezpośredniego związku przyczynowego między Toothache a Catch.
\end{itemize}

\subsubsection{Przykład 2}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.99]{psi26.png}}
\end{figure}

W domu zainstalowano nowy alarm antywłamaniowy. Jest dość niezawodny w wykrywaniu włamania, ale czasami reaguje również na niewielkie trzęsienia ziemi. Masz również dwóch sąsiadów, Johna i Mary, którzy obiecali zadzwonić do ciebie w pracy, gdy usłyszą alarm. John prawie zawsze dzwoni, gdy słyszy alarm, ale czasami myli dzwonek telefonu z budzikiem i wtedy też dzwoni. Mary natomiast lubi głośną muzykę i często zupełnie nie reaguje na alarm. Biorąc pod uwagę historię tego kto dzwonił lub nie dzwonił, chcielibyśmy oszacować prawdopodobieństwo włamania.

Struktura sieci na obrazku obok, pokazuje, że włamanie i trzęsienia ziemi bezpośrednio wpływają na prawdopodobieństwo uruchomienia alarmu, ale to, czy John i Mary zadzwonią, zależy tylko od alarmu. Sieć reprezentuje zatem nasze założenia, że Mary i John nie dostrzegają bezpośrednio włamań oraz nie zauważają niewielkich trzęsień ziemi.

Graf nie ma węzłów dla których 'JohnCalls' lub 'Mary Calls' byliby rodzicami (np. 'Mary słuchająca muzyki' lub 'John mylący telefon z alarmem'). To właśnie dlatego krawędzie idące z 'Alarm' do 'JohnCalls' i 'Mary Calls' mają przypisaną do siebie niepewność. Podejście takie powoduje że model staje się bardziej uniwersalny, ponieważ przez wprowadzenie niepewności bierzemy pod uwagę wszystkie czynniki losowe takie które potencjalnie mogłyby wpłynąć np. na działanie alarmu (wysoka wilgotność, awaria zasilania, rozładowany akumulator, przecięte przewody, martwa mysz utknięta w dzwonku itp.). W ten sposób mały agent może poradzić sobie z bardzo dużym światem. Stopień przybliżenia można poprawić, jeśli wprowadzimy dodatkowe istotne informacje. 

\subsection{Uczenie Bayesowskie}

 Ideą uczenia Bayesowskiego jest wyliczenie rozkładu prawdopodobieństwa parametrów wyjściowych nowego przypadku pod warunkiem jego parametrów wejściowych i wszystkich przypadków treningowych. Załóżmy, że nowy przypadek ma parametr wejściowy $X=x$ (który będziemy zapisywać jako $x$) i parametr wyjściowy $Y$. Celem będzie policzenie $P(Y | x \wedge E)$, gdzie $E$ jest zbiorem treningowym przypadków. 


\subsection{Wnioskowanie probabilistyczne}

Jest to obliczanie prawdopodobieństw następujących dla propozycji zapytań, biorąc pod uwagę zaobserwowane dowody. 

\begin{figure}[H]
\centerline{\includegraphics[scale=0.99]{psi27.png}}
\end{figure}


\subsubsection{Marginalizacja}

Proces uzyskania rozkładu na jakiś podzbiór zmiennych albo na jedną zmienną, aby uzyskać prawdopodobieństwo marginalne, za pomocą sumowania prawdopodobieństwa dla każdej możliwej wartości innych/pozostałych zmiennych, tym samym usuwając je z równania.\\

np. prawdopodobieństwo marginalne próchnicy: $P(cavity) = 0.108+0.012+0.072+0.008$ 

\newpage
\section{Kartkówka 4 - Programowanie z ograniczeniami}

Programowanie z ograniczeniami służy do rozwiązywania tzw. CSP (constraint satisfaction problem), czyli problemów spełnienia ograniczeń. Najpierw zdefiniujemy sobie trochę formalniej CSP, a następnie przejdziemy do metod służących do rozwiązywania CSP. Aby opisać CSP będą nam potrzebne pojęcia przedstawione poniżej.  

\subsection{Pojęcia podstawowe}

\subsubsection{Zmienna algebraiczna}
Zmienna określa pewną cechę opisywanego przez nas świata (np. wzrost człowieka, stan włącznika itp.), zmienne zapisujemy dużymi literami, np. $X,Y$.

\subsubsection{Dziedzina}
Każda zmienna algebraiczna ma przypisaną do niej dziedzinę, którą oznaczamy $dom(X)$. Dziedzina to zbiór wartości, które może przyjmować zmienna. \\

Zmienne dzielimy na 
\begin{itemize}
\item dyskretne - wartości w tej dziedzinie są skończone lub przeliczalnie skończone
\item binarne - dwie wartości w dziedzinie
\item ciągłe - wartości z osi liczb rzeczywistych
\end{itemize}

\subsubsection{Przypisanie}
Przypisanie to po prostu nadanie zmiennej wartości z jej dziedziny. Przypisanie totalne to nadanie każdej ze zmiennych wartości z jej dziedziny. \\
Formalnie przypisanie jest funkcją, która każdej zmiennej przypisuje wartość z jej dziedziny. 

\subsubsection{Ograniczenie (hard constraint)}

Twarde/Silne ograniczenie (tłumaczenie własne, ang. hard constraint) lub po prostu ograniczenie ogranicza możliwe przypisania wartości do zmiennych poprzez określenie warunków, które określają czy dane przypisanie jest możliwe czy nie. Możemy mówić o ograniczeniach unarnych (na jedną zmienną), binarnych(dwie zmienne) oraz k-arnych (na wiele zmiennych). \\

Sposoby definiowanie ograniczeń:
\begin{itemize}
\item \textbf{Intension} - polega na zdefiniowaniu ograniczenia poprzez użycie symboli logicznych
\item \textbf{Extension} - polega na wypisaniu wszystkich przypisań, które są poprawne
\end{itemize}  

Przykład \\
Mamy dane zmienne $\{X,Y,Z\}$, każda z nich ma dziedzinę $\{1,2,3,4\}$.  \\
Przykładowe ograniczenie typu \textbf{intension}: 
\begin{figure}[H]
\centerline{\includegraphics[scale=0.99]{psi28.png}}
\end{figure}

Przykładowe ograniczenie typu extension:
\begin{figure}[H]
\centerline{\includegraphics[scale=0.99]{psi29.png}}
\end{figure}

\subsubsection{Constraint Satisfaction Problem CSP}

Teraz gdy mamy już bazę pojęć możemy sobie trochę formalniej powiedzieć czym jest CSP. \\

CSP Constraint Satisfaction Problem składa się z:
\begin{itemize}
\item zbioru zmiennych
\item dziedziny dla każdej ze zmiennych
\item zbioru ograniczeń
\end{itemize}

Możemy mówić o skończonych CSP oraz nieskończonych CSP, skończone CSP to takie, które posiadają skończony zbiór zmiennych i skończoną dziedzinę dla każdej ze zmiennych. \\

Przykład zadania z ograniczeniami \\

Robot w fabryce musi wykonywać określone czynności w celu wytworzenia produktu, oznaczmy je \textit{a,b,c,d,e}. Każda z czynności może zostać wykonana w jednej z chwil czasu, które oznaczamy \textit{1,2,3,4}. Zmiennymi w naszym zadaniu będą czasy w których robot wykonał daną czynność, i tak przez \textit{A} będziemy oznaczać czas w jakim robot wykonał czynności \textit{a}. Dodatkowo chcemy aby zawsze spełnione były następujące zasady: 

\begin{figure}[H]
\centerline{\includegraphics[scale=0.65]{psi30.png}}
\end{figure}

Nasze zadanie z ograniczeniami ma więc postać: \\
\begin{itemize}
\item Zmienne: \textit{A,B,C,D,E}
\item Dziedzina: 
\begin{figure}[H]
\centerline{\includegraphics[scale=0.65]{psi31.png}}
\end{figure}
\item Ograniczenia
\begin{figure}[H]
\centerline{\includegraphics[scale=0.65]{psi30.png}}
\end{figure}
\end{itemize}

\subsubsection{Model dla CSP}
Modelem dla CSP nazywamy takie przypisanie (czyli nadanie każdej ze zmiennych wartości z jej dziedziny), które jest zgodne ze wszystkimi ograniczeniami. Mając zadanie CSP, wiele informacji dotyczących modelu będzie dla nas ważne:
\begin{itemize}
\item Czy model istnieje ?
\item Znalezienie modelu
\item Ile jest modeli ?
\item Znalezienie najlepszego modelu pod względem przyjętej metryki
\end{itemize}

W naszych dalszych rozważaniach skupimy się głównie na prezentacji metod które dadzą nam informacje o postaci modelu (o ile istnieje). Niektóre z metod pozwolą także na określenie czy model nie istnieje lub na znalezienie wszystkich możliwych modeli. 

\subsection{Metody rozwiązywania CSP}

\subsubsection{Generate-and-Test Algorithms}
Nie wiem jaki będzie polski odpowiednik... przegląd zupełny (?) - W tym algorytmie chodzi o to, że sprawdzamy wszystkie możliwe przypisania po kolei, jeśli znajdziemy zgodne z ograniczeniami, to jest ono naszym znalezionym modelem. Zaletą tej metody jest oczywiście prostota, a wadą to, że jest ona możliwa do zastosowania tylko dla małych problemów. Jeśli mamy n zmiennych, które mają dziedziny o rozmiarze d, to wszystkie możliwe kombinacje to $d^n$. 

\subsubsection{Search}
W metodzie Generate-and-Test przypisywaliśmy \underline{każdej} zmiennej bez wyjątku wartość, a później sprawdzaliśmy to z ograniczeniami. Zastanówmy się jednak czy jest to zawsze konieczne. Jeśli wiemy, że przypisanie danej wartości do danej zmiennej narusza któreś z ograniczeń, to nie ma sensu przypisywać wartości do innych zmiennych oraz badać czy spełniają one ograniczenia - nasz model i tak nie będzie poprawny. Ta prosta obserwacja jest podstawą metody Search (Przeszukiwanie (?)). \\

Przeszukiwanie reprezentujemy w formie grafu w którym każdy z węzłów reprezentuje przypisanie wartości do jakiejś zmiennej (poza startowym, węzeł startowy nie reprezentuje przypisania). Jak to działa:
\begin{itemize}
\item Będąc w danym węźle wybierz dowolną zmienną, która nie ma w nim żadnej przypisanej wartości
\item Przetestuj wszystkie możliwe przypisania wartości do tej zmiennej z jej dziedziny
\item Jeśli po przypisaniu do nowej zmiennej wartości, całe przypisanie spełnia ograniczenia, to tworzy ono nowy węzeł
\end{itemize} 

Trudno to zrozumieć na podstawie opisu więc spójrzmy na przykład, bo w rzeczywistości algorytm działania jest bardzo prosty:

\begin{figure}[H]
\centerline{\includegraphics[scale=0.65]{psi32.png}}
\end{figure}

Jak widzimy w drzewie interesują nas tylko końcowe węzły, to one są przypisaniem, które jest naszym modelem. \\

Przeszukiwanie takiego grafu np. przy pomocy algorytm depth-first search, czyli tzw. \textbf{backtracking} może być o wiele szybsze niż stosowanie metody Generate-and-Test. Metoda ta jest jednak nieco bardziej skomplikowana niż Generate-and-Test, ceną prostoty mamy szybkość działania. 

 
\subsubsection{Consistency algorithms}

Consistency algorithms (algorytmy spójności (?)) polegają na badaniu dziedziny zmiennych i sprawdzaniu czy można z nich usunąć jakieś wartości, ponieważ są nieosiągalne ze względu na ograniczenia. Jak to rozumieć ? Spójrzmy na przykład: \\

Mamy dane zadanie z ograniczeniami w którym:
\begin{itemize}
\item Zmienne: \textit{A,B}
\item Dziedziny: $dom(A)=dom(B)=\{1,2,3,4\}$
\item Ograniczenia: $\{A<B\}$
\end{itemize}

Sprawdźmy dowolne przypisanie w którym $A=4$, czy takie przypisanie jest w ogóle sens sprawdzać ? Łatwo można zauważyć, że nie, ponieważ $A<B$, a wiemy na podstawie dziedziny, że $A$ oraz $B$ są co najwyżej równe 4. Co możemy w takim razie zrobić ? Wiedząc o takiej \textbf{niespójności dziedziny} możemy usunąć z dziedziny zmiennej $A$ wartość 4, tak aby przy przeszukiwaniu nie musieć sprawdzać wszystkich możliwości dla których $A=4$, czyli zmieniamy dziedzinę poprzez usunięcie z niej niespójności tak aby otrzymać \textbf{spójną dziedzinę}, czyli nasza dziedzina będzie wyglądać tak: $dom(A)=\{1,2,3\}$. Taka jest ogólna idea algorytmu, ale jak to zalgorytmizować, bo przecież nie będziemy się opierać na spostrzeżeniach, prawda ? \\

W celu algorytmizacji tego algorytmu stosujemy graf nazywany siecią ograniczeń. Graf taki budujemy w następujący sposób:

\begin{itemize}
\item Każdy węzeł o kształcie okręgu to zmienna
\item Każdy węzeł o kształcie prostokąta to ograniczenie
\item Jeśli zmienna występuje w ograniczeniu, to rysujemy krawędź nieskierowaną pomiędzy węzłem zmiennej, a węzłem ograniczenia
\end{itemize}

Przykład \\

Dane jest CSP w którym:
\begin{itemize}
\item Zmienne: $A,B,C$
\item Ograniczenia: $\{A<B, B<C\}$
\item Wartości: $dom(A)=dom(B)=dom(C)=\{1,2,3,4\}$
\end{itemize}
w kroku pierwszym dla każdej ze zmiennych i każdego z ograniczeń rysujemy węzeł. W kroku drugim łączymy krawędzią zmienne z ograniczeniami, które zawierają te zmienne.
\begin{figure}[H]
\centerline{\includegraphics[scale=0.65]{psi33.png}}
\end{figure}
Zauważmy, że czasem mogą się zdarzyć ograniczenia tylko z jedną zmienną, przykładowo $A\neq4$, wtedy do danego ograniczenia idzie tylko jedna krawędź z węzła $A$. \\

\begin{itemize}
\item \textbf{Szkic algorytmu i spójność krawędziowa} - sieć ograniczeń jest \textbf{spójną krawędziowo/gałęziowo} (arc consistent) jeśli każda z jej krawędzi jest spójna krawędziowo,
\item Gałąź jest \textbf{spójna krawędziowo} jeśli dla dla każdej wartości z dziedziny zmiennej, która łączy się z węzłem ograniczenia, istnieją takie wartości innych zmiennych, które również łączą się z tym ograniczeniem, że całe ograniczenie jest spełnione. Jeśli tak nie jest, to z dziedziny możemy usunąć wartość dla której nie ma odpowiadających wartości innych zmiennych.  
\end{itemize}

Algorytm ten możemy zastosować przed algorytmem Search aby wyeliminować z dziedziny niepotrzebne wartości. 

\subsubsection{Domain splitting lub inaczej case analysis}
Idea algorytmu polega na podziale dziedziny danej zmiennej na mniejsze podzbiory. Następnie problem rozwiązujemy zakładając, że zmienna znajduje się w jednym z tych podzbiorów, później, że w kolejnym itd. Jeśli znajdziemy rozwiązanie w jednym z podzbiorów, nie musimy przeglądać pozostałych. Nie trudno zauważyć, że metod jest pewną formą algorytmu Search, a więc nic nowego, ale metoda ta może też mieć ciekawe zastosowanie w połączeniu z \textit{Consistency algorithm}: \\

Jedną z efektywnych dróg rozwiązania CSP jest zastosowanie spójności krawędziowej do uproszczenia sieci przed każdym krokiem dzielenia dziedziny. 

\subsubsection{Variable elimination (VE)}
Metoda ta jest w pewnym sensie podobna do metody \textit{Domain splitting}. W metodzie \textit{Domain splitting} usuwaliśmy z dziedziny wartości dla danej zmiennej, z kolei w \textit{Variable elimination} usuwany całą zmienną z sieci. \\

Ogólna idea: \\

Metoda ta działa przez usunięcie z sieci zmiennej i zastąpienie tej zmiennej ograniczeniami nałożonymi na inne zmienne, które były powiązane ograniczeniami z usuwaną zmienną. Usuwana zmienna oraz wszystkie ograniczenia w której się zawiera są usuwane z sieci, za to pojawiają się w sieci nowe ograniczenia, których dotąd nie było, te nowe ograniczenia odzwierciedlają wpływa usuniętej zmiennej na sieć. \\

Ogólny schemat działania: \\

Metoda ta działa poprzez tworzenia łączeń (join) na możliwych wartościach zmiennych. Najpierw wypisujemy wszystkie możliwe kombinacje zmiennych dla usuwanej zmiennej oraz innych, które są z nią w jakieś relacji przez ograniczenia. Później robimy join przez wartości tej usuwanej zmiennej. Na koniec robimy join przez wartości zmiennych z ograniczeń. Wszystko to brzmi bardzo abstrakcyjnie więc zobaczmy to na przykładzie:

\begin{figure}[H]
\centerline{\includegraphics[scale=0.65]{psi34.png}}
\end{figure}


\subsubsection{Local search}

Te algorytmy przeszukują przestrzeń rozwiązań tylko w ograniczonym zakresie. Dedykowane są dla wielkich przestrzeni rozwiązań w których przeszukanie całej przestrzeni jest niemożliwe. Algorytmy te przeszukują tylko pewne fragmenty przestrzeni rozwiązań. Nie dają gwarancji, że rozwiązania zostanie znalezione nawet jeśli istnieje więc nie mogą udowodnić, że rozwiązanie nie istnieje (algorytmy, które dają gwarancje znalezienia rozwiązania jeśli istnieje nazywamy kompletnymi). Dobrze się sprawdzają w problemach w których z góry wiemy, że rozwiązanie istnieje. \\ 

Metody te działają najpierw przypisują każdej ze zmiennych jakąś wartość, a następnie dążą do poprawy przypisań iteracyjnie, poprzez wykonywanie przypisań zgodnie z przyjętą metodą generacji nowych rozwiązań. Dlatego właśnie mówimy tutaj o całej grupie algorytmów, ponieważ generacja nowych rozwiązań może być zrealizowana na wiele sposobów. Przy rozwiązywaniu danego problemu chcemy jak najlepiej dobrać metodę do rozwiązywanego zagadnienia. \\

My omówimy sobie dwie metody \textit{Local search}:
\begin{itemize}
\item \textit{Random sampling} - w metodzie tej na początku losowane jest losowe przypisanie totalne, a następnie w każdej iteracji całe przypisanie totalne jest losowane od nowa
\item \textit{Random walk} - w metodzie tej na początku losowane jest losowe przypisanie totalne, a następnie w każdej iteracji zmieniana jest losowa wartość tylko jeden zmiennej 
\end{itemize}

Każda z tych metod może przynosić lepsze rezultaty niż druga w zależności od tego jaki jest rozkład przestrzeni rozwiązań. 




\end{document}
